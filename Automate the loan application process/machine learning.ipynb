{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbef6a59-4994-4a48-b119-7b054cf7db97",
   "metadata": {},
   "source": [
    "# Basic Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "19dba917-6891-4c8e-9202-a23328a0bca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.79\n",
      "\n",
      "Confusion Matrix:\n",
      "[[18 25]\n",
      " [ 1 79]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.42      0.58        43\n",
      "        True       0.76      0.99      0.86        80\n",
      "\n",
      "    accuracy                           0.79       123\n",
      "   macro avg       0.85      0.70      0.72       123\n",
      "weighted avg       0.83      0.79      0.76       123\n",
      "\n",
      "\n",
      "Top 10 most important features:\n",
      "                     Feature  Importance\n",
      "4             Credit_History    0.189253\n",
      "0            ApplicantIncome    0.078834\n",
      "2                 LoanAmount    0.073886\n",
      "1          CoapplicantIncome    0.048769\n",
      "3           Loan_Amount_Term    0.035518\n",
      "625  Property_Area_Semiurban    0.019232\n",
      "619              Married_Yes    0.016902\n",
      "623   Education_Not Graduate    0.013505\n",
      "626      Property_Area_Urban    0.012581\n",
      "620             Dependents_1    0.012068\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# 1. Load data\n",
    "df = pd.read_csv(\"train_cleaned.csv\")\n",
    "\n",
    "# 3. Preprocessing\n",
    "# Check and encode categorical variables\n",
    "categorical_columns = df.select_dtypes(include=[\"object\"]).columns\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Separate features and target label\n",
    "X = df_encoded.drop(columns=[\"Loan_Status_Y\"], errors=\"ignore\")\n",
    "y = df_encoded[\"Loan_Status_Y\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4. Build the model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 5. Evaluate the model\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nAccuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# 6. Feature Importance\n",
    "importances = rf_model.feature_importances_\n",
    "feature_importance = pd.DataFrame({\n",
    "    \"Feature\": X.columns,\n",
    "    \"Importance\": importances\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 most important features:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a2cc56-5ab4-4631-9e16-158b1b3454b8",
   "metadata": {},
   "source": [
    "# Advanced Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "349fba66-6968-4b2c-ad60-5fc3693da6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.73\n",
      "\n",
      "Confusion Matrix:\n",
      "[[19 24]\n",
      " [ 9 71]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.68      0.44      0.54        43\n",
      "           Y       0.75      0.89      0.81        80\n",
      "\n",
      "    accuracy                           0.73       123\n",
      "   macro avg       0.71      0.66      0.67       123\n",
      "weighted avg       0.72      0.73      0.71       123\n",
      "\n",
      "\n",
      "Cross-Validation Scores: [0.78861789 0.7398374  0.79674797 0.76422764 0.7295082 ]\n",
      "Mean CV Accuracy: 0.76\n",
      "Standard Deviation of CV Accuracy: 0.03\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                    Feature  Importance\n",
      "2                LoanAmount    0.260163\n",
      "3          Loan_Amount_Term    0.155894\n",
      "1         CoapplicantIncome    0.109444\n",
      "4            Credit_History    0.092998\n",
      "0           ApplicantIncome    0.082510\n",
      "18  Property_Area_Semiurban    0.050343\n",
      "17      Property_Area_Rural    0.048479\n",
      "8               Married_Yes    0.024688\n",
      "19      Property_Area_Urban    0.023666\n",
      "7                Married_No    0.020925\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, cross_val_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"train_cleaned.csv\")\n",
    "\n",
    "# Split features and labels\n",
    "X = df.drop(columns=[\"Loan_Status\"], errors=\"ignore\")\n",
    "y = df[\"Loan_Status\"]\n",
    "\n",
    "# Drop unnecessary columns\n",
    "X = X.drop(columns=[\"Loan_ID\"], errors=\"ignore\")\n",
    "\n",
    "# Identify column types\n",
    "categorical_columns = X.select_dtypes(include=[\"object\"]).columns\n",
    "numerical_columns = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "\n",
    "# Preprocessing pipelines\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"pca\", PCA(n_components=0.95))\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numerical_pipeline, numerical_columns),\n",
    "        (\"cat\", categorical_pipeline, categorical_columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Full pipeline\n",
    "pipeline = ImbPipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"smote\", SMOTE(random_state=42)),\n",
    "    (\"classifier\", RandomForestClassifier(random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Hyperparameter tuning with RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'classifier__n_estimators': [50, 100, 150, 200],\n",
    "    'classifier__max_depth': [10, 20, None],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],\n",
    "    'classifier__max_features': ['sqrt', 'log2', None],\n",
    "    'classifier__bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=10,\n",
    "    cv=3,\n",
    "    scoring=\"accuracy\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = random_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nAccuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores = cross_val_score(random_search.best_estimator_, X, y, cv=5, scoring=\"accuracy\")\n",
    "print(\"\\nCross-Validation Scores:\", cv_scores)\n",
    "print(f\"Mean CV Accuracy: {cv_scores.mean():.2f}\")\n",
    "print(f\"Standard Deviation of CV Accuracy: {cv_scores.std():.2f}\")\n",
    "\n",
    "# Feature Importance\n",
    "rf_model = random_search.best_estimator_.named_steps[\"classifier\"]\n",
    "importances = rf_model.feature_importances_\n",
    "feature_names = (\n",
    "    numerical_columns.tolist() + \n",
    "    list(random_search.best_estimator_.named_steps[\"preprocessor\"].transformers_[1][1]\n",
    "         .named_steps[\"encoder\"].get_feature_names_out(categorical_columns))\n",
    ")\n",
    "feature_importance = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Importance\": importances\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b267c24-a09c-44f5-9b38-772166850fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
