{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0ccdfbe-5e4c-4bda-9111-eaf80752ae26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.05%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94      7952\n",
      "           1       0.64      0.41      0.50      1091\n",
      "\n",
      "    accuracy                           0.90      9043\n",
      "   macro avg       0.78      0.69      0.72      9043\n",
      "weighted avg       0.89      0.90      0.89      9043\n",
      "\n",
      "\n",
      "Feature Importances:\n",
      "age: 0.1034\n",
      "job: 0.0492\n",
      "marital: 0.0226\n",
      "education: 0.0279\n",
      "default: 0.0020\n",
      "balance: 0.1093\n",
      "housing: 0.0260\n",
      "loan: 0.0097\n",
      "contact: 0.0201\n",
      "day: 0.0897\n",
      "month: 0.0877\n",
      "duration: 0.2900\n",
      "campaign: 0.0384\n",
      "pdays: 0.0490\n",
      "previous: 0.0228\n",
      "poutcome: 0.0522\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv('train_cleaned.csv')\n",
    "\n",
    "# Identify the categorical columns\n",
    "categorical_columns = ['job', 'marital', 'education', 'default', \n",
    "                       'housing', 'loan', 'contact', 'month', 'poutcome', 'y']\n",
    "\n",
    "# Apply LabelEncoder automatically to each categorical column\n",
    "label_encoder = LabelEncoder()\n",
    "for col in categorical_columns:\n",
    "    df[col] = label_encoder.fit_transform(df[col])\n",
    "\n",
    "# Identify the feature columns (X) and the target column (y)\n",
    "X = df.drop('y', axis=1)  # Feature columns\n",
    "y = df['y']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets (80% - 20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Print detailed evaluation metrics (precision, recall, f1-score)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# If you want to check the feature importance\n",
    "feature_importances = rf_model.feature_importances_\n",
    "print(\"\\nFeature Importances:\")\n",
    "for feature, importance in zip(X.columns, feature_importances):\n",
    "    print(f\"{feature}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3b08df0-c488-410d-ac91-221bf69d8f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.41%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      7952\n",
      "           1       0.58      0.14      0.23      1091\n",
      "\n",
      "    accuracy                           0.88      9043\n",
      "   macro avg       0.74      0.56      0.58      9043\n",
      "weighted avg       0.86      0.88      0.85      9043\n",
      "\n",
      "Cross-Validation Accuracy: 77.57%\n",
      "Best Parameters from RandomizedSearchCV: {'classifier__n_estimators': 100, 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 1, 'classifier__max_depth': None, 'classifier__bootstrap': False}\n",
      "\n",
      "Feature Importances:\n",
      "age: 0.0324\n",
      "job: 0.0278\n",
      "marital: 0.0187\n",
      "education: 0.1447\n",
      "default: 0.0081\n",
      "balance: 0.0219\n",
      "housing: 0.0093\n",
      "loan: 0.0001\n",
      "contact: 0.0006\n",
      "day: 0.0005\n",
      "month: 0.0004\n",
      "duration: 0.0013\n",
      "campaign: 0.0007\n",
      "pdays: 0.0010\n",
      "previous: 0.0017\n",
      "poutcome: 0.0014\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Read the data\n",
    "df = pd.read_csv('train_cleaned.csv')\n",
    "\n",
    "# Define the categorical columns\n",
    "categorical_columns = ['job', 'marital', 'education', 'default', \n",
    "                       'housing', 'loan', 'contact', 'month', 'poutcome', 'y']\n",
    "\n",
    "# Apply LabelEncoder automatically to each categorical column\n",
    "label_encoder = LabelEncoder()\n",
    "for col in categorical_columns:\n",
    "    df[col] = label_encoder.fit_transform(df[col])\n",
    "\n",
    "# Define the feature columns (X) and target column (y)\n",
    "X = df.drop('y', axis=1)  # Feature columns\n",
    "y = df['y']  # Target column\n",
    "\n",
    "# Split the data into training and testing sets (80% - 20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build a pipeline for preprocessing and the model\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', SimpleImputer(strategy='mean'), X.select_dtypes(include=['float64', 'int64']).columns),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), X.select_dtypes(include=['int64']).columns)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with preprocessing and Random Forest model\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Define parameters for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'classifier__n_estimators': [50, 100],  # Decrease the number of trees\n",
    "    'classifier__max_depth': [10, 20, None],\n",
    "    'classifier__min_samples_split': [2, 5],\n",
    "    'classifier__min_samples_leaf': [1, 2],\n",
    "    'classifier__bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(pipeline, param_distributions=param_dist, n_iter=5, cv=3, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Train the model with RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = random_search.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Print detailed classification metrics (precision, recall, f1-score)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Cross-validation (Reduce the number of folds to 3)\n",
    "cv_scores = cross_val_score(random_search.best_estimator_, X, y, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "print(f'Cross-Validation Accuracy: {cv_scores.mean() * 100:.2f}%')\n",
    "\n",
    "# Print the best parameters from RandomizedSearchCV\n",
    "print(f\"Best Parameters from RandomizedSearchCV: {random_search.best_params_}\")\n",
    "\n",
    "# If you want to check the feature importances\n",
    "feature_importances = random_search.best_estimator_.named_steps['classifier'].feature_importances_\n",
    "print(\"\\nFeature Importances:\")\n",
    "for feature, importance in zip(X.columns, feature_importances):\n",
    "    print(f\"{feature}: {importance:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1138be6-973d-46e6-bc7d-31612e520359",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
